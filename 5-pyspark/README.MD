# PySpark

### 1. About PySpark

Apache Spark is written in Scala programming language. To support Python with Spark, Apache Spark community released a tool, **PySpark**. Using PySpark, you can work with RDDs in Python programming language also. It is because of a library called Py4j that they are able to achieve this. This is an introductory tutorial, which covers the basics of Data-Driven Documents and explains how to deal with its various components and sub-components. [More...](https://www.tutorialspoint.com/pyspark/index.htm)

### 2. How did i install PySpark?

**java**

`sudo apt install default-jre`

`sudo apt install openjdk-11-jre-headless`

`sudo apt install openjdk-8-jre-headless`

**scala**

`sudo apt install scala`


